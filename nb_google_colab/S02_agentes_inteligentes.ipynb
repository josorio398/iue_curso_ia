{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S02_agentes_inteligentes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzCssL32ykAhl2kSbixRzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssanchezgoe/iue_curso_ia/blob/main/nb_google_colab/S02_agentes_inteligentes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  <tr>\n",
        "     <th><p><img alt=\"Colaboratory logo\" height=\"120 px\" src=\"http://www.redttu.edu.co/es/wp-content/uploads/2016/01/iue.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p></th> \n",
        "     <th><h1>  Agentes Inteligentes y Resolución de problemas mediante búsqueda I </h1></th>\n",
        "  </tr>\n"
      ],
      "metadata": {
        "id": "qYlZdlAFgQOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentes Inteligentes"
      ],
      "metadata": {
        "id": "big5N6irgqHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción\n",
        "\n",
        "Identificaremos el concepto de **agente racional** como elemento central de la inteligencia artificial y cuyo concepto concretaremos en esta sección. Se estudiará tambien lo que es la racionalidad y como se puede aplicar a una amplia variedad de agentes que operan en cualquier medio. La idea es utilizar este concepto para desarrollar un pequeño conjunto de principios de diseño que sirvan para construir agentes útiles.\n",
        "\n",
        "Empezaremos por examinar los agentes, los medios en los que se desenvuelven, y la interacción entre éstos. La idea de que algunos agentes se comportan mejor que otros nos lleva a la nocion de **agente racional**: aquel que se comporta tan bien como puede. La forma de actuar del agente depende de la naturaleza del medio; algunos entornos pueden ser más complejos que otros. Se proporciona una categorización cruda del medio y se muestra cómo las propiedades de un entorno influyen en el diseño de agentes adecuados para ese entorno. Se presenta un número de **esquemas** básicos para el diseño de agentes."
      ],
      "metadata": {
        "id": "LE1kPYwgg0KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agentes y entorno\n",
        "\n",
        "Un agente corresponde a cualquier ente con la capacidad de **percibir su entorno** mediante la ayuda de **sensores** para poder realizar acciones mediante **actuadores**. En la siguiente gráfica se ilustran estos conceptos involucrados.\n",
        "\n",
        "<center><img src='https://github.com/ssanchezgoe/iue_curso_ia/blob/main/imagenes/S02_Agente.png?raw=true'></center>\n",
        "\n",
        "Algunos ejemplos prácticos de agéntes se muestran a continuación:\n",
        "\n",
        "1. Por ejemplo, en una fabrica automatizada de producción de carros, un conjunto de brazos robóticos perciben su entorno mediante cámaras con el objetivo de construir carros.\n",
        "\n",
        "\n",
        "<center><img src='https://i.gifer.com/83WH.gif'></center>\n",
        "\n",
        "\n",
        "2. Un algoritmo capaz de jugar al ajedrez con un humano, percibe como entrada los movimentos que realiza un humano y propone una partida para ganarle.\n",
        "\n",
        "<center><img src = 'https://images.chesscomfiles.com/uploads/v1/images_users/tiny_mce/pdrpnht/phpf0cMEm.gif'></center> \n",
        "\n",
        "3. Un agente humano con ojos, oídos y otros órganos sensoriales además de manos, piernas, boca y otras partes del cuerpo para realizar acciones.\n",
        "\n",
        "El concepto de **percepción** se utiliza en este contexto para indicar que el agente puede recibir entradas en cualquier momento. La secuencia de percepciones de un agente refleja el historial de lo que el agente ha recibido.\n",
        "\n",
        "De forma matemática se puede decir que el conjunto de acciones de un agente esta data por **La función del agente** que proyecta una percepción dada a una acción, o al menos una parte si se trata de un número muy grande de acciones.\n",
        "\n",
        "\n",
        "En principio, la función que describe a un agente se puede expresar en *forma de tabla*; aunque infinita en la mayoría de casos, se podría limitar el tamaño de la secuencia de percepciones para describir parte de la función. La tabla puede ser construida para un agente, con el que se requiere experimentar, registrando todas las secuencias de percepción y la respuesta en forma de acción respectiva. \n",
        "\n",
        "Veamos como podemos crear una tabla que describa la función de un agente mediante un ejemplo sencillo. Consideremos una aspiradora con dos casillas (Casilla A y B) donde debe limpiar. Supongamos que la aspiradora tiene un sistema de cámaras que percibe su entorno, es decir, si una casilla se encuentra sucia o no. Una función sencilla del agente estaría dada por las siguientes instrucciones:\n",
        "\n",
        "- Si la casilla en la que se encuentra está sucia, entonces deberá aspirarla.\n",
        "- Si la casilla en la que se encuentra está limpia, moverse a otra casilla. \n",
        "\n",
        "En la siguiente tabla se muestran las definiciones de uno o varios agentes partiendo de alguna de las casillas (A o B):\n",
        "\n",
        "Secuencia de percepciones | Acción\n",
        "-- | --\n",
        "[A, Limpio] | Derecha\n",
        "[A, Sucio] | Aspirar\n",
        "[B, Limpio] | Izquierda\n",
        "[A, Limpio], [A, Sucio] | Aspirar\n",
        ". | .\n",
        ". | .\n",
        ". | .\n",
        "[A, Limpio], [A, Limpio], [A, Limpio] | Derecha\n",
        "[A, Limpio], [A, Limpio], [A, Sucio] | Aspirar\n",
        ". | .\n",
        ". | .\n",
        ". | .\n",
        " \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P99r4mDpnNJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ejercicio: Realice una tabla de la definición funcional del agente robot en el ejemplo de una fabrica automatizada de producción de carros. Despliegue una celda de texto para crear una tabla.\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZDErMQymSK41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buen comportamiento: Noción de racionalidad"
      ],
      "metadata": {
        "id": "lRl06NdJTGJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decimos que un **agente es racional** si hace lo correcto, es decir, cada secuencia de la tabla de la definición funcional es realizada correctamente. Por tanto, se necesita determinar una forma de medir el éxito"
      ],
      "metadata": {
        "id": "QE4kVlGpi_d_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medidas de rendimiento\n",
        "\n",
        "Las **medidas de rendimiento** establecen los criterios que determinan el exito de un agente. Cuando el agente está en un entorno, se generan una secuencia de acciones de acuerdo a las percepciones que tiene. Estas secuencias hace que el ambiente cambie de estado: por ejemplo si las casillas A y B de ejemplo anterior estan sucias, los estados por los que transita el entorno serán:\n",
        "\n",
        "1. [A,Sucio], [B, Sucio]\n",
        "2. [A,Limpio], [B, Sucio]\n",
        "2. [A,Limpio], [B, Limpio]\n",
        "\n",
        "a medida que el agente realiza las diferentes acciones. Si las secuencias son las deseadas, entonces decimos que el agente actua correctamente. En este caso, podemos tener una medida más objetiva del rendimiento como la cantidad de suciedad limpiada en un periodo de tiempo.\n",
        "\n",
        "Estas medidas podrían resultar engañosas: por ejemplo, el agente podría devolver la suciedad y recogerla continuamente para ganar puntos. Tendríamos que pensar entonces en una medida de rendimiento que recompence al agente por la mayor cantidad de cuadrículas limpias en el menor tiempo posible. \n",
        "\n",
        "Como regla general se tiene que *es mejor diseñar medidas de utilidad de acuerdo con lo que se quiere para el entorno, más que de acuerdo con cómo se cree que el agente debe comportarse*."
      ],
      "metadata": {
        "id": "De5GL0lzlCdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ejercicio: Discuta en clase que médida de rendimiento podría implementarse para el agente robot en la fábrica de construcción automatizada de carros."
      ],
      "metadata": {
        "cellView": "form",
        "id": "KRek2jywqarc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Racionalidad\n",
        "\n",
        "La racionalidad en un momento determinado depende de cuatro factores:\n",
        "1. La medida de rendimiento que define el criterio de éxito.\n",
        "2. El conocimiento del entorno en el que habita acumulado por el agente. \n",
        "3. Las acciones que el agente puede llevar a cabo.\n",
        "4. La secuencia de percepciones del agente hasta este momento.\n",
        "\n",
        "De lo anterior se deriva la siguiente definición de **agente racional**\n",
        "\n",
        "*En cada posible secuencia de percepciones, un agente racional deberá emprender aquella acción que suponga una maximixación de su medida de rendimiento, basándose en las evidencias aportadas por la secuencia de percepciones y en el conocimiento que el agente mantiene almacenado*."
      ],
      "metadata": {
        "id": "rJnaJannrm7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Omnisciencia, aprendizaje y autonomía\n",
        "\n",
        "Junto al concepto de nreacionalidad nacen los conceptos de omnisciencia, aprendizaje y autonomía, que pueden ser consultados en la referencia [Inteligencia artificial: Un enfoque moderno](http://jdelagarza.fime.uanl.mx/IA/Libros/inteligencia-artificial-un-enfoque-moderno-stuart-j-russell.pdf)."
      ],
      "metadata": {
        "id": "PRA1qxgAqaCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naturaleza del entorno\n",
        "\n",
        "Un **entorno de trabajo** se define como el problema o conjunto de problemas que resolverá el agente inteligente. "
      ],
      "metadata": {
        "id": "MlfXPlu4zq6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Especificación del entorno de trabajo\n",
        "\n",
        "Un **entorno de trabajo** está constituido por \n",
        "\n",
        "1. Medidas de **R**endimiento. R\n",
        "2. El **E**ntorno.             E\n",
        "3. Los **A**ctuadores.         A\n",
        "4. Los **S**ensores.           S\n",
        "\n",
        "Cuando se diseñe un agente siempre se debe tener en cuenta antes el entorno de trabajo.\n",
        "\n",
        "Por ejemplo, si fuesemos a definir el entorno de trabajo en la conducción autómata, requeriríamos de los siguientes elementos resumidos en la siguiente tabla:\n",
        "\n",
        "\n",
        "Tipo de Agente | Medidas de **R**endimiento | **E**ntorno | **A**ctuadores | **S**ensores\n",
        "--|--|--|--|--\n",
        "Conductor autómata  | Seguro, rápido, legal,<br> viaje confortable, maximi-<br>zación del beneficio | Carreteras, otro tráfico,<br> peatones, clientes | Dirección, acelerador, <br>freno, señal, bocina, <br>visualizador | Cámaras, sónar, velo-<br>címetro, GPS, tacómetro,<br> visualizador de la aceleración,<br> sensores del motor, teclado\n",
        "\n"
      ],
      "metadata": {
        "id": "KW2Nrjhn0Ed6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ejercicio: Elija uno de los siguientes casos y determine el entorno de trabajo:\n",
        "variable_name = \"Sistema diagnostico medico\" #@param [\"Sistema diagnostico medico\", \"Sistema de analisis de imagenes satelital\", \"Robot para la seleccion de componentes\", \"Controlador de una refineria\", \"Instructor de ingles interactivo\"]\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5fPNJHI84Xjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Propiedades de los entornos de trabajo\n",
        "\n",
        "Alguna de las propiedades o dimensiones de los entornos de trabajo son:\n",
        "\n",
        "- **Totalmente observable vs parcialmente observable**: Si los sensores del agente le proporcionan acceso a todos los estados del entorno, decimos entonces que es **totalmente observable**. Si los sensores son poco exactos, no se puede mapear todos los estados del entorno, a lo que llamamos **parcialmente observable**.\n",
        "\n",
        "- **Determinsta vs estocástico**: Si el estado de medio está totalmente determinado por el estado actual y la acción ejecutada por el agente, entonces se dice que el entorno es determinista; de lo contrario, decimos que es estocástico. Si pensamos en un robot que tiene que subir cierto número de escaleras para llegar a un lugar, entonces, cada estado (escalón) y cada acción (subir) determinan el siguiente estado (siguiente escalon); por otra parte, si pensamos en lanzamientos consecutivos de un dado, cada número obtenido (estado) es independiente del anterior. Por otra parte, si el medio es determinista, excepto para las acciones de otros agentes, entonces decimos que es **estatégico**.\n",
        "\n",
        "- **Episódico vs secuencial**: En los entornos de trabajo episódicos, la experiencia del agente se divide en episodios atómicos. Cada episodio consiste en la percepción del agente y la realización de única tarea, y los episodios y acciones son independientes de las otras. Por ejemplo, si se tiene un agente para seleccionar piezas defectuosas en una cadena de producción, las acciones tomadas con cada pieza son independietes entre si. En los entornos de trabajo secuenciales, las decisión tomada en un momento, puede afectar las decisiones en el futuro. Por ejemplo, en el caso de la conducción autómata, resulta evidente que la decisión tomada en un instante, puede afectar las decisiones futuras.\n",
        "\n",
        "- **Estático vs dinámico**: En caso de que el entorno pueda cambiar cuado el agente está realizando una acción, entonces decirmos que el entorno es dinámico; en caso contrario, hablamos de un entorno estático. Por otra parte, si el entorno no cambia con el tiempo sino que el rendimiento del agente lo hace, nos referimos al medio como **semidinámico**.\n",
        "\n",
        "- **Discreto vs continuo**: Podemos distinguir estos dos tipos a través de la forma en que se caracteriza al *tiempo*, las *percepciones* y las *acciones*. En un juego de ajedrez, se tiene un número finito de estados, y las percepciones y acciones son discretas. Por otra parte, en el caso de la conducción autómata, el tiempo es de caracter continuo así como la acción de conducción. Por otra parte, el sistema de visión es, estrictamente, discreto, aunque se trata como un problema continuo. \n",
        "\n",
        "- **Agente individual vs multiagente**: La diferencia entre agente individual y multiagente radica en si, dentro del entorno, existen relaciones o no con más agentes. Un ajente que realice un crucigrama puede tomarse como *agente invidual*. Respecto al caso multiagente, pueden surgir dos tipos de relaciones que se den en un entorno entre dos o más agentes:\n",
        "    - Competitivo: Cuando, por ejemplo, un agente intenta maximizar su medida de rendimiendo a costa de minimiza la de otro.\n",
        "    - Coperativo: Cuando se intenta maximizar las medidas de rendimiento de los agentes involucrados. "
      ],
      "metadata": {
        "id": "hawlmSkB50LN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estructura de los agentes.\n",
        "\n",
        "Hasta el momento solo hemos drescrito los agentes en términos de su *conducta*, es decir, para una secuencia de percepciones se realiza una acción. Cabe preguntarnos entonces ¿cómo trabaja internamente un agente?. El trabajo dentro de la inteligencia artificial consiste en desaroollar el **programa del agente** el cual toma las percepciones como entradas y realiza una accion (o acciones). El agente estará compuesto entonces por una serie de sensosores, acoplados a un computador (con movimiento, en caso de requerirlo), y cuyas percepciones entran a un programa y conformar los actuadores. Al conjunto de  de computador, sensores y actuadores se le conoce como **arquitectura**. Un agente, puede espresarse como:\n",
        "\n",
        "$$\\text{Agente} = \\text{arquitectura} + \\text{programa}$$\n",
        "\n",
        "Respecto a los programas para agentes, existen cuatro tipos básicos en los que se basan casi que todos los sistemas inteligentes:\n",
        "\n",
        "- Agentes reactivos simples.\n",
        "- Agentes reactivos basados en modelos.\n",
        "- Agentes reactivos basados en objetivos.\n",
        "- Agentes reactivos basados en utilidad.\n",
        "\n",
        "Los cuales veremos a continuación."
      ],
      "metadata": {
        "id": "aDVy0OrM6xQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentes reactivos simples\n",
        "\n",
        "Los **agentes reactivos simples** son aquellos en los que se toma un conjunto de percepciones para realiza una acción, ingnorándose el resto de percepciones historicas. Por ejemplo, el ejemplo de la aspiradora, correspondría a un agente reactivo simple. \n",
        "\n",
        "Un ejemplo de psedocódigo se presenta a continuación:\n",
        "\n",
        "<center><img src='https://github.com/ssanchezgoe/iue_curso_ia/blob/main/imagenes/S02_programa_aspiradora.png?raw=true'></center>\n",
        "\n",
        "\n",
        "Como puede observar, la acción \"aspirar\" solo se realiza si el estado de la casilla es \"sucio\". Así mismo, moverse a \"derecha\" o \"izquierda\" solo se realiza en caso que el la localización de la aspiradora es \"A\" o \"B\", respectivamente. En cualquier caso, tenemos una dupla cono **regla condición-acción**.\n"
      ],
      "metadata": {
        "id": "cu6bTGPcAjZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentes reactivos basados en modelos\n",
        "\n",
        "\n",
        "La forma más efectiva que tienen los agentes de manejar la visibilidad parcial es alma- cenar información de las partes del mundo que no pueden ver. O lo que es lo mismo, el agente debe mantener algún tipo de **estado interno** que dependa de la historia percibida y que de ese modo refleje por lo menos alguno de los aspectos no observables del estado actual.\n",
        "\n",
        "La actualización de la información de estado interno según pasa el tiempo requiere codificar dos tipos de conocimiento en el programa del agente:\n",
        "\n",
        "1. Cómo evoluciona el entorno con el tiempo.\n",
        "2. Cuales son las consecuencias de las acciones a realizar por el agente.\n",
        "\n",
        "Primero, se necesita alguna información acerca de cómo evoluciona el entorno independientemente del agente. Segundo, se necesita más información sobre cómo afectan al entorno las acciones del agente. Para determinar estos estados futuros, se requiere de modelos que lo predigan. Un agente que utilice este modelo es un **agente basado en modelos**."
      ],
      "metadata": {
        "id": "zGWkERD6E3Za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentes reactivos basados en objetivos\n",
        "\n",
        "El conocimiento sobre el estado actual del mundo no es siempre suficiente para decidir qué acción tomar. Por ejemplo, en un cruce de vías, un conductor puede girar en cualquier sentido o seguir recto. La acción adecuada está supeditada a donde se quiera ir. En otras palabras, además de la descripción del estado actual, el agente necesita algún tipo de información sobre su meta. El programa del agente se puede combinar con información sobre los resultados de las acciones posibles para elegir las acciones que permitan alcanzar el objetivo.\n",
        "\n",
        "En algunas ocasiones, la selección de acciones basadas en objetivos es directa, cuando se alcanzan los objetivos después de una acción individual. En otras ocasiones, puede ser más complicado, cuando el agente tiene que considerar secuencias complejas para encontrar el camino que le permita alcanzar el objetivo. Los problemas de **Búsqueda** y **planificación** son los subcampos de la IA centrados en encontrar secuencias de acciones que permitan a los agentes alcanzar sus metas.\n"
      ],
      "metadata": {
        "id": "JUW9Sno1E79_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentes reactivos basados en utilidad\n",
        "\n",
        "Las metas por sí solas no son realmente suficientes para generar comportamiento de gran calidad en la mayoría de los entornos. Por ejemplo, hay muchas secuencias de acciones que llevarán al taxi a su destino (y por tanto a alcanzar su objetivo), pero algunas son más rápidas, más seguras, más fiables, o más baratas que otras. Las metas sólo proporcionan una cruda distinción binaria entre los estados de «felicidad» y «tristeza», mientras que una medida de eficiencia más general debería permitir una comparación entre estados del mundo diferentes de acuerdo al nivel exacto de felicidad que el agente alcance cuando se llegue a un estado u otro. Como el término «felicidad» no suena muy científico, la terminología tradicional utilizada en estos casos para indicar que se prefiere un estado del mundo a otro es que un estado tiene más utilidad que otro para el agente.\n",
        "\n",
        "Una función de utilidad proyecta un estado (o una secuencia de estados) en un número real, que representa un nivel de felicidad. La definición completa de una función de utilidad permite tomar decisiones racionales en dos tipos de casos en los que las me- tas son inadecuadas. Primero, cuando haya objetivos conflictivos, y sólo se puedan alcanzar algunos de ellos (por ejemplo, velocidad y seguridad), la función de utilidad de- termina el equilibrio adecuado. Segundo, cuando haya varios objetivos por los que se pueda guiar el agente, y ninguno de ellos se pueda alcanzar con certeza, la utilidad pro- porciona un mecanismo para ponderar la probabilidad de éxito en función de la impor- tancia de los objetivos.\n",
        "En el Capítulo 16, se mostrará cómo cualquier agente racional debe comportarse como si tuviese una función de utilidad cuyo valor esperado tiene que maximizar. Por tanto, un agente que posea una función de utilidad explícita puede tomar decisiones raciona- les, y lo puede hacer con la ayuda de un algoritmo de propósito general que no dependa de la función específica de utilidad a maximizar. De esta forma, la definición «global» de racionalidad (identificando como racionales aquellas funciones de los agentes que pro- porcionan el mayor rendimiento) se transforma en una restricción «local» en el diseño de agentes racionales que se puede expresar con un simple programa.\n",
        "La Figura 2.14 muestra la estructura de un agente basado en utilidad. En la Parte IV aparecen programas de agentes basados en utilidad, donde se presentan agentes que to- man decisiones y que deben trabajar con la incertidumbre inherente a los entornos par- cialmente observables.\n"
      ],
      "metadata": {
        "id": "OytrTD8UJ154"
      }
    }
  ]
}